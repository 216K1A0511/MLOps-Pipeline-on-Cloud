services:
  mlops-pipeline:
    build: .
    container_name: gemini-mlops
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LOG_LEVEL=INFO
      - PIPELINE_ENV=production
      - USE_MOCK=true # Default to Mock Mode for robustness
    volumes:
      - ./data:/app/data
      - ./models:/app/models
      - ./logs:/app/logs
      - ./reports:/app/reports
    command: python -m src.pipeline.pipeline --task-type classification --use-mock

  mlops-api:
    build: .
    container_name: gemini-mlops-api
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - API_HOST=0.0.0.0
      - API_PORT=8080
      - USE_MOCK=true
    volumes:
      - ./models:/app/models
      - ./logs:/app/logs
    ports:
      - "8080:8080"
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/health" ]
      interval: 30s
      timeout: 10s
      retries: 3
    command: python -m src.inference.api_server

  mlops-monitor:
    build: .
    container_name: gemini-mlops-monitor
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./reports:/app/reports
    command: python -m src.monitoring.performance_tracker --watch

  mlops-scheduler:
    image: alpine:latest
    container_name: mlops-scheduler
    command: |
      sh -c "
      echo 'Starting scheduler...' &&
      while true; do
        curl -X POST http://mlops-pipeline:8080/trigger-training 2>/dev/null || true;
        sleep 86400;
      done
      "
    depends_on:
      - mlops-pipeline
