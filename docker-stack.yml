version: '3.8'

services:
  mlops-api:
    image: 216k1a0511/mlops-pipeline:latest
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - API_HOST=0.0.0.0
      - API_PORT=8080
    ports:
      - "8081:8080"
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
    command: python -m src.inference.api_server

  mlops-pipeline:
    image: 216k1a0511/mlops-pipeline:latest
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - LOG_LEVEL=INFO
      - PIPELINE_ENV=production
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    command: python -m src.pipeline.pipeline --task-type classification

  mlops-monitor:
    image: 216k1a0511/mlops-pipeline:latest
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
    command: python -m src.monitoring.performance_tracker --watch
